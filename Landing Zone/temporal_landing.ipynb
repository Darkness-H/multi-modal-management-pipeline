{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22ef85b-bbe6-415b-a01e-ad70923728c7",
   "metadata": {},
   "source": [
    "## Temporal landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1bfceb-07ca-4bb5-bf57-72e15dd5c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9617c1c6-3d38-4c4e-a696-898c30a86620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful dependencies\n",
    "import io\n",
    "import ast\n",
    "import boto3\n",
    "import requests\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44f238a-5c7e-4edb-a9e5-469cd7d1ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 client for MinIO (MinIO implements Amazon S3 API)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://127.0.0.1:9000\", # MinIO API endpoint\n",
    "    aws_access_key_id=\"minioadmin\", # User name\n",
    "    aws_secret_access_key=\"minioadmin\", # Password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98986f43-e9ca-4da5-8e9c-3c0d53b7ba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset 1 contains 83560 rows\n",
      "The dataset 2 contains 889793 rows\n"
     ]
    }
   ],
   "source": [
    "# We are going to use two datasets, one from: https://huggingface.co/datasets/FronkonGames/steam-games-dataset (123 MB)\n",
    "ds1_raw = load_dataset(\"FronkonGames/steam-games-dataset\")\n",
    "# The other one from: https://huggingface.co/datasets/atalaydenknalbant/rawg-games-dataset (998 MB)\n",
    "ds2_raw = load_dataset(\"atalaydenknalbant/rawg-games-dataset\")\n",
    "\n",
    "# Print the number of rows of each dataset\n",
    "print(f\"The dataset 1 contains {ds1_raw['train'].num_rows} rows\")\n",
    "print(f\"The dataset 2 contains {ds2_raw['train'].num_rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3fc011-d497-436d-974e-0b8bfdd597e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subdataset 1 contains 100 rows\n",
      "The subdataset 2 contains 100 rows\n"
     ]
    }
   ],
   "source": [
    "# We are going to use the first 100 rows from each dataset for testing purposes\n",
    "ds1 = ds1_raw['train'][0:100]\n",
    "ds2 = ds2_raw['train'][0:100]\n",
    "\n",
    "# Print the number of rows of each subdataset\n",
    "print(f\"The subdataset 1 contains {len(ds1['About the game'])} rows\")\n",
    "print(f\"The subdataset 2 contains {len(ds2['description'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7311a18-3e40-4976-bbd6-dc6c5bb30fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested on Text, Image and Video data\n",
    "# We can find each of these data in the following columns\n",
    "# ds1: \"About the game\" (Text), \"Header image\" (Image), \"Screenshots\" (Image), \"Movies\" (Video)\n",
    "# ds2: \"description\" (Text), \"background_image\" (Image), \"background_image_additional\" (Image), \"short_screenshots\" (Image)\n",
    "# By combing both datasets, we assume there will be duplicates of games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617ce3a-ad0a-4a6b-bc76-e9e2819b97ed",
   "metadata": {},
   "source": [
    "**Uploading Texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dff938-2722-49f9-9a1f-770bf7a29266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uploads each game description from strings to the given bucket_name,\n",
    "# saving them as separate text files (text_1.txt, text_2.txt, â€¦).\n",
    "def upload_strings_separately(bucket_name, client, strings, path=\"temporal-landing/\", prefix=\"text\"):\n",
    "    for i, s in enumerate(strings, start=1):\n",
    "        if not s: # skip empty strings or None\n",
    "            continue\n",
    "        object_name = f\"{path}{prefix}_{i}.txt\" # temporal-landing/text_1.txt, temporal-landing/text_2.txt ...\n",
    "        client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=object_name,\n",
    "            Body=io.BytesIO(s.encode(\"utf-8\")),\n",
    "            ContentType=\"text/plain\"\n",
    "        )\n",
    "\n",
    "# Uploading text files (combining both datasets)\n",
    "upload_strings_separately(\"landing-zone\", s3, strings = \n",
    "                          ds1['About the game'] +\n",
    "                          ds2['description'],\n",
    "                          path = \"temporal-landing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b8dd7-52c9-433c-8d61-f369f407b54e",
   "metadata": {},
   "source": [
    "**Uploading Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93316e9e-60cf-4cb5-b018-7fc10aa63b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fields \"Screenshots\" from ds1 and \"short_screenshots\" from ds2 need to be cleaned first.\n",
    "\n",
    "# ds1\n",
    "ds1ss = [] # Flatten into a clean list of URLs\n",
    "for item in ds1['Screenshots']:\n",
    "    if not item:\n",
    "        continue\n",
    "    ds1ss.extend([url.strip() for url in item.split(\",\") if url.strip()])\n",
    "\n",
    "# ds2\n",
    "ds2ss = [] # Extract image URLs\n",
    "for elem in ds2['short_screenshots']:\n",
    "    if not elem:\n",
    "        continue\n",
    "    records = elem.split('|') # Split the string by '|'\n",
    "    for rec in records:\n",
    "        # Convert string to dict safely\n",
    "        d = ast.literal_eval(rec)\n",
    "        ds2ss.append(d['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd859e6-2b94-4ea1-83cf-192d288dbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function downloads URL in links as a stream and uploads it directly to the given bucket,\n",
    "# saving the files with names like image_1.jpg, image_2.png, etc., while preserving their extensions.\n",
    "def upload_media_from_links(bucket_name, client, links, path=\"temporal-landing/\", prefix=\"image\"):\n",
    "    for i, url in enumerate(links, start=1):\n",
    "        if not url:\n",
    "            continue\n",
    "        \n",
    "        # Stream download to avoid loading full file in memory\n",
    "        with requests.get(url, stream=True, timeout=60) as r:\n",
    "            r.raise_for_status() # check for HTTP errors\n",
    "            ext = url.split('.')[-1].split('?')[0] # get file extension\n",
    "            object_name = f\"{path}{prefix}_{i}.{ext}\"\n",
    "            # This streams the request directly to MinIO without creating a full BytesIO object\n",
    "            client.upload_fileobj(\n",
    "                Fileobj=r.raw,\n",
    "                Bucket=bucket_name,\n",
    "                Key=object_name,\n",
    "                ExtraArgs={\"ContentType\": f\"{prefix}/{ext}\"}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "564651dc-319c-41d3-b5f2-9297245bc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image files (combining both datasets)\n",
    "upload_media_from_links(\"landing-zone\", s3, links = \n",
    "                         ds1['Header image'] + ds2['background_image'], #+ ds2['background_image_additional'] + ds1ss + ds2ss,\n",
    "                         path=\"temporal-landing/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de2b3d-ceb1-4327-a93a-23b39939e2e9",
   "metadata": {},
   "source": [
    "**Uploading Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8e8cab-c17c-4ee7-9f00-d79c7ffabd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading video files\n",
    "upload_media_from_links(\"landing-zone\", s3, links = \n",
    "                         ds1['Movies'][0:5], # We can only upload a few videos due to MinioIO storage size\n",
    "                         path=\"temporal-landing/\", prefix = \"video\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
